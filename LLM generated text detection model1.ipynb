{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeBqar53Bavf",
    "outputId": "ecf418d2-4d89-4450-836f-4e5de6c7438b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mTue Sep 30 02:57:00 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   36C    P8             11W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# 필수 라이브러리 설치 (Colab)\n",
    "!pip install -q --upgrade transformers peft accelerate datasets evaluate scikit-learn bitsandbytes\n",
    "\n",
    "# GPU 정보 확인\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksWMdyKWBgXI"
   },
   "outputs": [],
   "source": [
    "import os, random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"  # KoELECTRA 분류\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/LikeLion_NLP2/Small_Challenge/koelectra_lora_out\"\n",
    "MAX_LEN = 512            # 문단이 길면 384~512, 더 길면 슬라이딩 윈도우 사용할수도?\n",
    "VAL_SIZE = 0.1           # 검증데이터셋 비율\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1GPl24DCZFY",
    "outputId": "533ccfb9-2953-4ece-f8cf-a36314d05f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/content/drive/MyDrive/LikeLion_NLP2/Small_Challenge/train.csv', encoding='utf-8-sig')\n",
    "test = pd.read_csv('/content/drive/MyDrive/LikeLion_NLP2/Small_Challenge/test.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "5lGB6LScCFcv",
    "outputId": "88d13035-2747-43da-eab5-2824ed948c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87454, 2) (9718, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 87454,\n  \"fields\": [\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 87454,\n        \"samples\": [\n          \"\\uc5d0\\ub529\\ud134 \\ud55c\\uacc4\\ub77c\\uace0\\ub3c4 \\ud45c\\ud604\\ub418\\ub294 \\uc5d0\\ub529\\ud134 \\uad11\\ub3c4\\ub294 (\\ud56d\\uc131 \\uac19\\uc740)\\ubb3c\\uccb4\\uac00 \\uc678\\ubd80\\ub85c \\uc791\\uc6a9\\ud558\\ub294 \\ubcf5\\uc0ac\\ub825\\uacfc \\uc548\\ucabd\\uc73c\\ub85c \\uc791\\uc6a9\\ud558\\ub294 \\uc911\\ub825\\uc774 \\ud3c9\\ud615\\uc744 \\uc774\\ub8e8\\ub294 \\uc0c1\\ud0dc\\uc5d0 \\uc788\\uc744 \\ub54c \\ub3c4\\ub2ec\\ud560 \\uc218 \\uc788\\ub294 \\ucd5c\\ub300 \\uad11\\ub3c4\\uc774\\ub2e4. \\ud3c9\\ud615 \\uc0c1\\ud0dc\\ub294 \\uc720\\uccb4 \\uc815\\uc5ed\\ud559\\uc801 \\ud3c9\\ud615\\uc774\\ub77c\\uace0 \\ubd88\\ub9b0\\ub2e4. \\ubcc4\\uc774 \\uc5d0\\ub529\\ud134 \\uad11\\ub3c4\\ub97c \\ub118\\uc5b4\\uc11c\\uba74, \\ubcc4\\uc740 \\ub9e4\\uc6b0 \\uac15\\ub82c\\ud55c \\ubcf5\\uc0ac\\ub85c \\uc778\\ud574 \\ud56d\\uc131\\ud48d\\uc73c\\ub85c \\uc790\\uc2e0\\uc758 \\ubc14\\uae65\\uce35\\uc744 \\ub0a0\\ub824\\ubc84\\ub9b0\\ub2e4. \\ub300\\ubd80\\ubd84\\uc758 \\ubb34\\uac70\\uc6b4 \\ubcc4\\ub4e4\\uc740 \\uc5d0\\ub529\\ud134 \\uad11\\ub3c4\\ubcf4\\ub2e4 \\ud6e8\\uc52c \\uc791\\uc740 \\uad11\\ub3c4\\ub97c \\uac00\\uc9c0\\uace0 \\uc788\\uae30 \\ub54c\\ubb38\\uc5d0, \\uc774\\ub4e4\\uc758 \\ud56d\\uc131\\ud48d\\uc740 \\ub300\\ubd80\\ubd84 \\ub35c \\uac15\\ub82c\\ud55c \\uc120 \\ud761\\uc218\\uc5d0 \\uc758\\ud574 \\ubc1c\\uc0dd\\ud55c\\ub2e4. \\uc5d0\\ub529\\ud134 \\ud55c\\uacc4\\ub294 \\ud018\\uc774\\uc0ac\\ucc98\\ub7fc \\uad00\\uce21\\ub41c \\uac15\\ucc29\\uc911\\uc778 \\ube14\\ub799\\ud640\\uc758 \\uad11\\ub3c4\\ub97c \\uc124\\uba85\\ud558\\uae30 \\uc704\\ud574 \\uc5b8\\uae09\\ub41c\\ub2e4. \\n \\uc6d0\\ub798 \\uc544\\uc11c \\uc2a4\\ud0e0\\ub9ac \\uc5d0\\ub529\\ud134 \\uacbd\\uc740 \\uc774 \\ud55c\\uacc4\\ub97c \\uc720\\ub3c4\\ud560 \\ub54c \\uc624\\uc9c1 \\uc804\\uc790 \\uc0b0\\ub780\\ub9cc\\uc744 \\uace0\\ub824\\ud588\\ub294\\ub370, \\uc624\\ub298\\ub0a0\\uc5d0\\ub294 \\uadf8\\uac83\\uc744 \\uace0\\uc804\\uc801\\uc778 \\uc5d0\\ub529\\ud134 \\ud55c\\uacc4\\ub77c\\uace0 \\ubd88\\ub9b0\\ub2e4. \\uc624\\ub298\\ub0a0\\uc758 \\uc218\\uc815\\ub41c \\uc5d0\\ub529\\ud134 \\ud55c\\uacc4\\ub294 \\uc18d\\ubc15-\\uc790\\uc720\\uc640 \\uc790\\uc720-\\uc790\\uc720 \\ubcf5\\uc0ac \\uc0c1\\ud638\\uc791\\uc6a9(\\uc81c\\ub3d9\\ubcf5\\uc0ac \\ucc38\\uace0)\\uacfc \\uac19\\uc740 \\ub2e4\\ub978 \\ubcf5\\uc0ac \\uacfc\\uc815\\uc744 \\uace0\\ub824\\ud558\\uace0 \\uc788\\ub2e4. \\n \\uc5d0\\ub529\\ud134 \\ud55c\\uacc4\\ub294 \\ud56d\\uc131\\uc758 \\ubc14\\uae65\\ucabd\\uc73c\\ub85c \\uc791\\uc6a9\\ud558\\ub294 \\ubcf5\\uc0ac\\uc555\\uc774 \\uc548\\ucabd\\uc73c\\ub85c \\uc791\\uc6a9\\ud558\\ub294 \\uc911\\ub825\\uacfc \\uac19\\uc544\\uc11c \\uc11c\\ub85c \\uc0c1\\uc1c4\\ub418\\ub294 \\uc9c0\\uc810\\uc5d0 \\uc124\\uc815\\ub41c\\ub2e4. \\ub450 \\ud798\\uc740 \\ubaa8\\ub450 \\uc5ed\\uc81c\\uacf1 \\ubc95\\uce59\\uc5d0 \\ub530\\ub77c \\uac10\\uc18c\\ud55c\\ub2e4. \\n \\uc815\\uc5ed\\ud559\\uc801 \\ud3c9\\ud615 \\uc0c1\\ud0dc\\uc5d0\\uc11c\\uc758 \\uc624\\uc77c\\ub7ec \\ubc29\\uc815\\uc2dd\\uc5d0\\uc11c \\ud3c9\\uade0 \\uac00\\uc18d\\ub3c4\\uac00 0\\uc784\\uc744 \\uc2dd\\uc73c\\ub85c \\ub098\\ud0c0\\ub0b4\\uba74 \\n \\uc555\\ub825\\uc774 \\ubcf5\\uc0ac \\uc120\\uc18d formula_6\\uc758 \\ubcf5\\uc0ac\\uc555\\uc5d0 \\uc758\\ud574 \\uc88c\\uc6b0\\ub41c\\ub2e4\\uba74 \\n \\uc774\\uace0, \\uc774\\ub54c formula_8\\ub294 \\ud56d\\uc131\\uc744 \\uad6c\\uc131\\ud558\\ub294 \\ubb3c\\uc9c8\\uc758 \\ubd88\\ud22c\\uba85\\ub3c4\\uc774\\ub2e4. \\n \\uc774\\uc81c \\ubd88\\ud22c\\uba85\\ub3c4\\ub97c \\uc0c1\\uc218\\ub77c\\uace0 \\uac00\\uc815\\ud558\\uace0 \\uac00\\uc6b0\\uc2a4 \\uc815\\ub9ac\\uc640 \\ud478\\uc544\\uc1a1 \\ubc29\\uc815\\uc2dd\\uc744 \\ud1b5\\ud574 \\n \\uc774\\ub807\\uac8c \\ud574\\uc11c \\uad6c\\ud574\\uc9c4 \\uad11\\ub3c4\\ub97c \\uc5d0\\ub529\\ud134 \\uad11\\ub3c4\\ub77c\\uace0 \\ud55c\\ub2e4. \\uc804\\ub9ac\\uc218\\uc18c\\ub85c\\ub9cc \\uc774\\ub8e8\\uc5b4\\uc9c4 \\ud56d\\uc131\\uc77c \\uacbd\\uc6b0 \\uc5d0\\ub529\\ud134 \\uad11\\ub3c4\\ub294 \\n \\uc5d0\\ub529\\ud134 \\uad11\\ub3c4\\ub294 \\uc5b4\\ub5a4 \\uad11\\uc6d0\\uc774 \\uc815\\uc5ed\\ud559\\uc801 \\ud3c9\\ud615\\uc744 \\uc720\\uc9c0\\ud558\\uba74\\uc11c \\ub0bc \\uc218 \\uc788\\ub294 \\ucd5c\\ub300\\uc758 \\uad11\\ub3c4\\uc774\\ub2e4. \\uad11\\ub3c4\\uac00 \\uc5d0\\ub529\\ud134 \\uad11\\ub3c4\\ud55c\\uacc4\\ub97c \\ub118\\uc5b4\\uc11c\\uba74, \\ubcf5\\uc0ac\\uc555\\uc774 \\uc911\\ub825\\uc744 \\uc774\\uae30\\uae30 \\ub54c\\ubb38\\uc5d0 \\ubb3c\\uc9c8\\ub4e4\\uc774 \\ubc14\\uae65\\uc73c\\ub85c \\uc0c8\\uc5b4\\ub098\\uac00\\uac8c \\ub41c\\ub2e4. \\n \\uc5d0\\ub529\\ud134 \\ud55c\\uacc4\\uc5d0 \\uadfc\\uc811\\ud558\\uac70\\ub098 \\ub118\\ub294 \\ud56d\\uc131\\ub4e4. \\n \\ubcf4\\ud1b5\\uc758 \\ud56d\\uc131\\ub4e4\\uc740 \\uc5d0\\ub529\\ud134 \\ud55c\\uacc4\\ubcf4\\ub2e4 \\uc9c8\\ub7c9\\uc774 \\ub9e4\\uc6b0 \\uc801\\uc5b4 \\ud3c9\\ud615 \\uc0c1\\ud0dc\\ub97c \\uc720\\uc9c0\\ud55c\\ub2e4. \\ud558\\uc9c0\\ub9cc \\ucd5c\\uadfc \\ub4e4\\uc5b4 \\uba87\\uba87\\uc758 \\uadf9\\ub300\\uac70\\uc131\\uacfc \\uc6b8\\ud504-\\ub808\\uc774\\uc5d0\\ubcc4\\ub4e4\\uc758 \\uc9c8\\ub7c9\\uacfc \\uad11\\ub3c4\\uac00 \\uc5d0\\ub529\\ud134 \\ud55c\\uacc4\\uc5d0 \\uadfc\\uc811\\ud558\\uac70\\ub098 \\ub118\\ub294\\ub2e4\\ub294 \\uc0ac\\uc2e4\\uc774 \\ubc1d\\ud600\\uc84c\\ub2e4.\",\n          \"\\uc870\\uc9c0 \\ubc84\\ub098\\ub4dc \\uc1fc \\uc791\\uc73c\\ub85c <\\ucca0\\ud559\\uc801 \\ud76c\\uadf9>\\uc774\\ub780 \\ubd80\\uc81c\\ub85c\\uc11c \\uc1fc\\uc758 \\uc0dd\\uba85\\ub825\\uc778 \\ucca0\\ud559\\uc744 \\uc8fc\\uc81c\\ub85c \\ud55c\\ub2e4. \\uadf8\\ub294 \\ubaa8\\uc131\\ubcf8\\ub2a5\\uc774\\uc57c\\ub9d0\\ub85c \\uc778\\ub958\\uc9c4\\ud654\\uc758 \\uc6d0\\ucc9c\\uc778 \\uc0dd\\uba85\\ub825\\uc758 \\ud45c\\ud604\\uc774\\uba70 \\ub530\\ub77c\\uc11c \\uc5f0\\uc560\\uc5d0 \\uc788\\uc5b4\\uc11c\\ub294 \\uc5ec\\uc131\\uc774 \\uc0ac\\ub0e5\\uafbc\\uc774\\uace0 \\ub0a8\\uc131\\uc740 \\ub178\\ud68d\\ubb3c\\uc774\\ub77c \\ud55c\\ub2e4. \\uc8fc\\uc778\\uacf5 \\uc874 \\ub2e4\\ub098\\ub294 \\uc564 \\uc704\\ud2b8\\ud544\\ub4dc\\uc5d0 \\ucad3\\uae30\\uc5b4 \\uac15\\uc81c\\ub85c \\uacb0\\ud63c\\ud55c\\ub2e4\\ub294 \\u2018\\ub3c8 \\ud6c4\\uc548 \\ud14c\\ub178\\ub9ac\\uc624\\u2019\\uc758 \\ud604\\ub300\\ud310\\uc774\\ub2e4. \\uc81c3\\ub9c9 \\uafc8\\uc758 \\uc7a5\\uba74\\uc740 <\\uc9c0\\uc625\\uc758 \\ub3c8 \\uc8fc\\uc559>\\uc73c\\ub85c\\uc11c \\ub2e8\\ub3c5\\uc801\\uc73c\\ub85c \\uc0c1\\uc5f0\\ub418\\uace0 \\uc788\\ub2e4. \\n \\u201c\\ucca0\\ud559\\uc801 \\ud76c\\uadf9\\u201d\\uc774\\ub780 \\ubd80\\uc81c\\uac00 \\ubd99\\uc740 \\uc778\\uac04\\uacfc \\ucd08\\uc778\\uc5d0\\uc11c \\uc1fc\\ub294 \\ub0a8\\ub140\\uc758 \\uc0bc\\uac01 \\ub85c\\ub9e8\\uc2a4\\ub85c\\ubd80\\ud130 \\u201c\\ucd08\\uc778\\u201d\\uc73c\\ub85c \\ub300\\ud45c\\ub418\\ub294 \\ub2c8\\uccb4\\uc758 \\ucca0\\ud559 \\uc0ac\\uc0c1\\uc744 \\uc804\\uac1c\\ud574 \\ub098\\uac00\\uba70 \\uc801\\uc7ac\\uc801\\uc18c\\uc5d0 \\uc720\\uba38\\uc640 \\ub18d\\ub2f4\\uc744 \\ubc30\\uce58\\ud574 \\ud76c\\uadf9\\uc758 \\ucc28\\uc6d0\\uc744 \\ud55c \\ub2e8\\uacc4 \\ub04c\\uc5b4\\uc62c\\ub9b0\\ub2e4. \\ub4f1\\uc7a5\\uc778\\ubb3c\\ub4e4\\uc758 \\uae30\\uc9c0 \\ub118\\uce58\\ub294 \\ub300\\ud654, \\uc2ec\\ub3c4 \\uc788\\ub294 \\ud1a0\\ub860 \\uc18d\\uc5d0\\uc11c \\uc790\\uc5f0, \\ubcf8\\uc131\\uc774 \\ucd94\\ub3d9\\ud574 \\ub098\\uac00\\ub294 \\uc0dd\\uba85\\ub825 \\uc788\\ub294 \\uc0b6\\uc774 \\uc774\\uc0c1 \\uc0ac\\ud68c\\ub97c \\ub9cc\\ub4e4\\uc5b4 \\ub0b8\\ub2e4\\ub294 \\uc1fc\\uc758 \\uc624\\ub79c \\ucca0\\ud559\\uc801 \\uad00\\uc810\\uc744 \\ubc1c\\uacac\\ud560 \\uc218 \\uc788\\ub2e4. \\n \\ubc84\\ub098\\ub4dc \\uc1fc\\uc758 \\uc0ac\\uc0c1\\uc774 \\uc9d1\\uc57d\\ub41c \\uc774 \\uc791\\ud488\\uc740 \\uadf9\\uc758 \\uad6c\\uc870\\ubd80\\ud130 \\uc0c1\\ud669 \\uc124\\uc815, \\uadf9 \\uc911 \\ub300\\uc0ac\\uae4c\\uc9c0 \\uace0\\ub3c4\\uc758 \\uc0c1\\uc9d5\\uc131\\uc744 \\ud568\\ucd95\\ud558\\uace0 \\uc788\\ub2e4. \\uac8c\\ub2e4\\uac00 \\uc0b6\\uacfc \\uc8fd\\uc74c\\uc758 \\ubb38\\uc81c, \\ucc9c\\uad6d\\uacfc \\uc9c0\\uc625\\uc758 \\uad00\\uacc4 \\ub4f1 \\uc2ec\\uc624\\ud55c \\uc8fc\\uc81c \\ub54c\\ubb38\\uc5d0 \\ub2e4\\uc18c \\ub09c\\ud574\\ud558\\uac8c \\uc5ec\\uaca8\\uc9c0\\uae30\\ub3c4 \\ud55c\\ub2e4. \\ud558\\uc9c0\\ub9cc \\ubab0\\uc785\\uc744 \\ub192\\uc774\\ub294 \\uadf9\\uc801 \\ubc18\\uc804\\uacfc \\uc7ac\\uae30 \\ub118\\uce58\\ub294 \\ub300\\uc0ac\\ub294 \\ub3c5\\uc790\\ub97c \\uc0ac\\uc720\\uc758 \\uae38\\ub85c \\uc778\\ub3c4\\ud55c\\ub2e4. \\uadf8\\ub9ac\\uace0 \\uc564\\uacfc \\ud0dc\\ub108\\uc758 \\uacb0\\ud569\\uc73c\\ub85c \\ucd08\\uc778(Superman)\\uc774 \\ud0c4\\uc0dd\\ud558\\ub9ac\\ub77c\\ub294 \\uacb0\\ub9d0\\ubd80\\uc758 \\uc554\\uc2dc\\uc5d0 \\uc774\\ub974\\ub7ec \\ub3c5\\uc790\\ub294 \\uc1fc\\uac00 \\uad81\\uadf9\\uc801\\uc73c\\ub85c \\uc804\\ud558\\uace0\\uc790 \\ud55c \\uc9c4\\uc9dc \\uba54\\uc2dc\\uc9c0\\uc5d0 \\ub2ff\\uac8c \\ub41c\\ub2e4. \\n 1905\\ub144 \\uc601\\uad6d\\uc5d0\\uc11c \\ucd08\\uc5f0\\ub418\\uc5c8\\ub358 \\uff1c\\uc778\\uac04\\uacfc \\ucd08\\uc778\\uff1e\\uc740 \\ub7f0\\ub358\\uc758 \\ucf54\\ud2b8\\uadf9\\uc7a5\\uc5d0\\uc11c 176\\ud68c \\uc0c1\\uc5f0\\ub418\\uc5c8\\ub2e4. \\ucc38\\uace0\\ub85c \\ub2f9\\uc2dc \\ucd5c\\uace0\\uc758 \\ud765\\ud589 \\uae30\\ub85d\\uc740 \\uff1c\\uc544\\ubb34\\ub3c4 \\ubab0\\ub77c\\uff1e(149\\ud68c)\\uc640 \\uff1c\\uc874 \\ubd88\\uc758 \\ub2e4\\ub978 \\uc12c\\uff1e(121\\ud68c)\\uc774\\uc5c8\\ub2e4. \\uc1fc\\ub294 \\uff1c\\uc778\\uac04\\uacfc \\ucd08\\uc778\\uff1e\\uc73c\\ub85c \\uc2e0\\uc138\\ub300 \\uc9c0\\uc2dd\\uc778\\ub4e4\\uc758 \\uc6b0\\uc0c1\\uc73c\\ub85c \\ub5a0\\uc62c\\ub790\\uace0 \\uc774\\ud6c4 10\\uc5ec \\ub144\\uac04 \\uadf8 \\uc790\\ub9ac\\ub97c \\uc9c0\\ucf30\\ub2e4. \\uadf8\\uac00 20\\uc138\\uae30 \\ucd08\\ubd80\\ud130 1\\ucc28 \\uc138\\uacc4 \\ub300\\uc804 \\uc774\\ud6c4\\uc5d0 \\uc774\\ub974\\uae30\\uae4c\\uc9c0 \\uc80a\\uc740\\uc774\\ub4e4\\uc5d0\\uac8c \\ubbf8\\uce5c \\uc601\\ud5a5\\uc740 \\uc6f0\\uc2a4\\ub098 \\uccb4\\uc2a4\\ud0c0\\ud2bc, \\ubca8\\ub85d, \\uace8\\uc988\\uc6cc\\ub514, \\ubca0\\ub137 \\ub4f1 \\ub2f9\\uc2dc\\uc758 \\ub2e4\\ub978 \\uc778\\uae30 \\uc791\\uac00\\ub4e4\\uacfc\\ub294 \\ube44\\uad50\\uac00 \\uc548 \\ub420 \\ub9cc\\ud07c \\ub300\\ub2e8\\ud588\\ub2e4. \\n \\ud654\\uc774\\ud2b8\\ud544\\ub4dc \\uacbd\\uc774 \\uc8fd\\uc73c\\uba74\\uc11c \\ub538 \\uc564\\uc758 \\ud6c4\\uacac\\uc778\\uc73c\\ub85c \\ub85c\\ubc85 \\ub818\\uc2a4\\ub374\\uacfc \\uc7ad \\ud0dc\\ub108\\ub97c \\uc9c0\\ubaa9\\ud55c\\ub2e4. \\uc644\\uace0\\ud558\\uace0 \\ubcf4\\uc218\\uc801\\uc778 \\ub178\\uc778 \\ub85c\\ubc85 \\ub818\\uc2a4\\ub374\\uc740 \\uc790\\uc720\\uc8fc\\uc758\\uc790 \\ud0dc\\ub108\\ub97c \\ubabb\\ub9c8\\ub545\\ud574\\ud558\\uc9c0\\ub9cc \\uc564 \\ud654\\uc774\\ud2b8\\ud544\\ub4dc\\ub294 \\ud0dc\\ub108\\ub97c \\uc790\\uc2e0\\uc758 \\ubc30\\uc6b0\\uc790\\ub85c \\ub099\\uc810\\ud55c\\ub2e4. \\uc564\\uacfc\\uc758 \\uc0ac\\ub791\\uc740 \\ubb3c\\ub860 \\uacb0\\ud63c\\uc774\\ub77c\\ub294 \\uc81c\\ub3c4 \\uc790\\uccb4\\ub97c \\uacbd\\uba78\\ud558\\ub294 \\ud0dc\\ub108\\uc758 \\ub9c8\\uc74c\\uc744 \\ub3cc\\ub9ac\\uae30 \\uc704\\ud574 \\uc564\\uc740 \\uac16\\uc740 \\ubc29\\ubc95\\uc73c\\ub85c \\uadf8\\ub97c \\uc720\\ud639\\ud55c\\ub2e4. \\ud0dc\\ub108\\ub294 \\uc564\\uc5d0\\uac8c\\uc11c \\ub3c4\\ub9dd\\uce58\\ub4ef \\uc2a4\\ud398\\uc778\\uc73c\\ub85c \\ud5a5\\ud588\\ub2e4\\uac00 \\uc232\\uc5d0\\uc11c \\uc0b0\\uc801 \\ub5bc\\ub97c \\ub9cc\\ub098 \\ubd99\\uc7a1\\ud788\\ub294 \\uc2e0\\uc138\\uac00 \\ub41c\\ub2e4. \\uc774\\uc5b4\\uc9c0\\ub294 \\uafc8\\uc18d \\uc7a5\\uba74\\uc5d0\\uc11c\\ub294 \\ub3c8 \\uc8fc\\uc548\\uacfc \\uc11d\\uc0c1, \\uc11d\\uc0c1\\uc758 \\ub538 \\uc544\\ub098\\uac00 \\ub4f1\\uc7a5\\ud574 \\uc120\\uacfc \\uc545, \\ucc9c\\uad6d\\uacfc \\uc9c0\\uc625, \\ucc9c\\uc0ac\\uc640 \\uc545\\ub9c8\\ub97c \\uc8fc\\uc81c\\ub85c \\uaca9\\ub82c\\ud788 \\ud1a0\\ub860\\ud55c\\ub2e4. \\uafc8\\uc5d0\\uc11c \\uae6c \\ud0dc\\ub108\\ub294 \\uadf9\\uc801\\uc73c\\ub85c \\uc564\\uacfc \\uc7ac\\ud68c\\ud558\\uace0, \\uc564\\uc740 \\uacb0\\ud63c\\uc740 \\ubb3c\\ub860 \\uc544\\ubc84\\uc9c0\\uac00 \\ud0dc\\ub108\\ub97c \\ud6c4\\uacac\\uc778\\uc73c\\ub85c \\uc9c0\\ubaa9\\ud558\\ub3c4\\ub85d \\ud55c \\uac83\\uae4c\\uc9c0, \\ubaa8\\ub450\\uac00 \\uc564 \\uc790\\uc2e0\\uc758 \\uc758\\uc9c0\\uc600\\uc74c\\uc744 \\ubc1d\\ud788\\uba70 \\ud0dc\\ub108\\uc5d0\\uac8c \\uacb0\\ud63c\\uc744 \\uc885\\uc6a9\\ud55c\\ub2e4. \\uc564\\uc758 \\uac15\\ub825\\ud55c \\uc758\\uc9c0 \\uc55e\\uc5d0 \\ud0dc\\ub108\\ub3c4 \\uacb0\\uad6d \\uad74\\ubcf5\\ud558\\uace0 \\ub9cc\\ub2e4.\",\n          \"1953\\ub144 \\uc11c\\ub3c5 \\ucd1d\\uc120\\uc740 1953\\ub144 \\ub3c5\\uc77c\\uc5f0\\ubc29\\uacf5\\ud654\\uad6d\\uc5d0\\uc11c \\uce58\\ub7ec\\uc9c4 \\ucd1d\\uc120\\uc774\\ub2e4. \\n \\uc0ac\\ud68c\\ubbfc\\uc8fc\\ub2f9\\uc740 1952\\ub144 \\uae30\\uc874 \\ub2f9\\uc758\\uc7a5 \\ucfe0\\ub974\\ud2b8 \\uc288\\ub9c8\\ud5c8\\uc758 \\uc0ac\\ub9dd \\uc774\\ud6c4 \\uc0c8\\ub85c\\uc6b4 \\uc758\\uc7a5\\uc744 \\uc120\\ucd9c\\ud574\\uc57c\\ud588\\uc73c\\uba70, \\ud6c4\\uc784\\uc73c\\ub85c \\uc5d0\\ub9ac\\ud788 \\uc62c\\ub80c\\ud558\\uc6b0\\uc5b4\\uac00 \\uc120\\ucd9c\\ub418\\uc5c8\\ub2e4. \\uadf8\\ub7ec\\ub098 \\ubcc0\\ud654\\ubcf4\\ub2e4\\ub294 \\uc548\\uc815\\uc744 \\uc120\\ud0dd\\ud55c \\ub3c5\\uc77c \\uad6d\\ubbfc\\ub4e4\\uc740 20%p \\uaca9\\ucc28 \\uac00\\uae4c\\uc774 \\ub418\\ub294 \\ud45c\\ucc28\\ub85c \\uc555\\ub3c4\\uc801\\uc73c\\ub85c \\uae30\\ub3c5\\uad50\\ubbfc\\uc8fc\\uc5f0\\ud569\\uc744 \\uc120\\ud0dd\\ud558\\uc600\\ub2e4. \\uae30\\ub3c5\\uad50\\ubbfc\\uc8fc\\uc5f0\\ud569\\uc740 45%\\ub97c \\ub4dd\\ud45c\\ud588\\uc73c\\uba70, \\uc0ac\\ud68c\\ubbfc\\uc8fc\\ub2f9\\uc740 28%\\uc5d0 \\ubd88\\uacfc\\ud588\\ub2e4. \\ub610\\ud55c, \\uc774 \\ucd1d\\uc120\\uc740 \\ub3c5\\uc77c \\uc5ed\\uc0ac\\uc0c1 \\ucd5c\\ucd08\\ub85c \\ubd09\\uc1c4\\uc870\\ud56d\\uc758 \\uac1c\\ub150\\uc774 \\ub4f1\\uc7a5\\ud588\\ub2e4. \\uc774\\ub54c\\ubd80\\ud130 \\ubd09\\uc1c4\\uc870\\ud56d\\uc740 \\uc9c0\\uc5ed\\uad6c \\uc758\\uc6d0\\uc744 \\uac00\\uc9c0\\uace0 \\uc788\\ub294 \\uc815\\ub2f9\\uc740 5%\\ub97c \\ub118\\uc9c0 \\uc54a\\uc544\\ub3c4 \\uc758\\uc11d\\uc744 \\ubc30\\ubd84\\ud558\\ub294 \\ud615\\uc2dd\\uc774\\uc5b4\\uc11c \\ud604\\ub300 \\ub3c5\\uc77c\\uc758 \\ubc29\\uc2dd\\uacfc\\ub294 \\ub2ec\\ub790\\uc9c0\\ub9cc, 5% \\ubd09\\uc1c4\\uc870\\ud56d \\uc870\\uc120\\uc740 \\ud604\\ub300\\uae4c\\uc9c0\\ub3c4 \\uc774\\uc5b4\\uc9c0\\uace0 \\uc788\\ub2e4. \\uc774 \\ubd09\\uc1c4\\uc870\\ud56d\\uc73c\\ub85c \\uc778\\ud574 \\ub3c5\\uc77c \\uacf5\\uc0b0\\ub2f9\\uc740 \\uc758\\uc11d\\uc744 \\ubaa8\\ub450 \\uc783\\uace0 \\uc0ac\\uc2e4\\uc0c1 \\ubd95\\uad34\\uc0c1\\ud0dc\\uc5d0 \\uc774\\ub974\\uac8c \\ub418\\uc5c8\\ub2e4. \\n \\uae30\\ub3c5\\uad50\\ubbfc\\uc8fc\\uc5f0\\ud569\\uc740 \\uacfc\\ubc18\\uc5d0 \\uac00\\uae4c\\uc6b4 \\uc758\\uc11d\\uc744 \\ucc28\\uc9c0\\ud588\\uc9c0\\ub9cc \\uc758\\uc11d\\uc774 \\ubaa8\\uc790\\ub790\\uae30 \\ub54c\\ubb38\\uc5d0 \\uc5f0\\uc815 \\ud30c\\ud2b8\\ub108\\ub97c \\uc120\\ud0dd\\ud574\\uc57c\\ud588\\ub2e4. \\ucf58\\ub77c\\ud2b8 \\uc544\\ub370\\ub098\\uc6cc\\ub294 \\ub3c5\\uc77c\\ub2f9, \\uc790\\uc720\\ubbfc\\uc8fc\\ub2f9\\uacfc \\uad8c\\ub9ac\\uc790 \\ud1f4\\ucd9c\\uc5f0\\ub300\\uc640 \\uc5f0\\uc815\\ud558\\uc600\\uace0, \\uc774\\ub85c \\uc778\\ud574 \\ubc18(\\u53cd) \\uc0ac\\ud68c\\uc8fc\\uc758 \\ub0b4\\uac01\\uc774 \\uad6c\\uc131\\ub418\\uc5c8\\ub2e4. \\uc815\\ubd80 \\uc758\\uc11d\\uc740 2/3\\uc774 \\ub118\\uc5c8\\uace0, \\uc0ac\\ud68c\\ubbfc\\uc8fc\\ub2f9\\uc740 \\uc6d0\\ub0b4\\uc5d0\\uc11c \\uace0\\ub9bd\\ub418\\uc5c8\\ub2e4. \\n \\ud55c\\ud3b8, \\uc774\\ud6c4 \\ub3c5\\uc77c \\uc911\\uc559\\uc815\\ubcf4\\uad6d\\uc5d0\\uc11c \\ub0b4\\ub193\\uc740 \\ud1b5\\uacc4\\uc5d0 \\ub530\\ub974\\uba74, 487\\uba85\\uc758 \\uc120\\ucd9c\\uc9c1 \\uc758\\uc6d0\\uc911 129\\uba85, \\uc804\\uccb4\\uc758 26.4%\\ub294 \\uc804\\uc5d0 \\ub098\\uce58\\ub2f9\\uc5d0\\uc11c \\ud65c\\ub3d9\\ud55c \\uc804\\uc801\\uc774 \\uc788\\uc5c8\\ub2e4\\uace0 \\ud55c\\ub2e4. \\ub300\\ud45c\\uc801\\uc778 \\uc0ac\\ub840\\uac00 \\ud6c4\\uc77c \\ub3c5\\uc77c\\uc758 \\ucd1d\\ub9ac\\uc9c1\\uae4c\\uc9c0 \\uc624\\ub974\\ub294 \\ucfe0\\ub974\\ud2b8 \\ud0a4\\uc9d5\\uac70\\uc774\\ub2e4. \\n \\uacbd\\uc81c \\uc7ac\\uac74\\uacfc \\uc911\\ub3c4 \\ubcf4\\uc218\\uc8fc\\uc758, \\uce5c\\ubbf8 \\ub4f1\\uc744 \\ub0b4\\uc138\\uc6b4 \\ub3c5\\uc77c \\uae30\\ub3c5\\uad50 \\ubbfc\\uc8fc\\uc5f0\\ud569, \\uc790\\uc720\\ubbfc\\uc8fc\\ub2f9, \\ub3c5\\uc77c\\ub2f9 \\ub4f1\\uc758 \\uc5ec\\uad8c\\uc774 \\uc555\\uc2b9\\ud558\\uba74\\uc11c \\uc7ac\\uc9d1\\uad8c\\uc5d0 \\uc131\\uacf5\\ud55c\\ub2e4.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-6f4200ca-4db8-4d15-b00a-5927f67c3e70\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13353</th>\n",
       "      <td>아메리칸 익스프레스 컴퍼니, 약칭 아멕스(\"AmEx\", \"Amex\")는 미국계 다국...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>장 담그기는 대한민국의 국가무형문화재 제137호이다. 장(醬)은 고추장, 된장, 간...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58382</th>\n",
       "      <td>이극감(李克堪)의 장남이자 이준경(李浚慶)의 조부이다. 무오사화 당시 김종직과 그의...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18605</th>\n",
       "      <td>츠비카우는 독일 동부 작센주에 있는 도시이다. \\n 작센 주 남부, 에르츠 산맥 기...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83834</th>\n",
       "      <td>김기홍은 대법원 판사를 역임한 법조인이다. 1981년 청주지방법원장에 임명된 오석낙...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f4200ca-4db8-4d15-b00a-5927f67c3e70')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6f4200ca-4db8-4d15-b00a-5927f67c3e70 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6f4200ca-4db8-4d15-b00a-5927f67c3e70');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-8ccaa559-420e-44da-84bd-976fd4e1e44c\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ccaa559-420e-44da-84bd-976fd4e1e44c')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-8ccaa559-420e-44da-84bd-976fd4e1e44c button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               full_text  generated\n",
       "13353  아메리칸 익스프레스 컴퍼니, 약칭 아멕스(\"AmEx\", \"Amex\")는 미국계 다국...          0\n",
       "5317   장 담그기는 대한민국의 국가무형문화재 제137호이다. 장(醬)은 고추장, 된장, 간...          0\n",
       "58382  이극감(李克堪)의 장남이자 이준경(李浚慶)의 조부이다. 무오사화 당시 김종직과 그의...          0\n",
       "18605  츠비카우는 독일 동부 작센주에 있는 도시이다. \\n 작센 주 남부, 에르츠 산맥 기...          0\n",
       "83834  김기홍은 대법원 판사를 역임한 법조인이다. 1981년 청주지방법원장에 임명된 오석낙...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 문자열 캐스팅 + 결측치 제거\n",
    "df[\"full_text\"] = df[\"full_text\"].astype(str).fillna(\"\")\n",
    "df[\"title\"] = df[\"title\"].astype(str).fillna(\"\")\n",
    "\n",
    "# Stratified split (라벨 비율 유지)\n",
    "train_df, valid_df = train_test_split(\n",
    "    df[[\"full_text\",\"generated\"]],\n",
    "    test_size=VAL_SIZE,\n",
    "    random_state=SEED,\n",
    "    stratify=df[\"generated\"]\n",
    ")\n",
    "\n",
    "print(train_df.shape, valid_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "f1158b0c59e64b1a8b06ff556ce8b258",
      "760e501a53084a3fbfcadd3e57dd7552",
      "0aa4a8fe357f498a9f77639a1b8d925f",
      "a8b3642aaad344b5879aecf243c5f603",
      "026161f30c8d4232a284e4c0c98dff8f",
      "560af9dbab464a45ba19b38d47a20c7a",
      "dc3cbffa5d094e2dbd008ad802a38b12",
      "a154ca5eb2794e459a9012f62497fe68",
      "e341df4d6e494142be2e393dbd042ee7",
      "7855212a4c0d40ab9ac78b2f75864956",
      "e4343c33560b4854bb4e5b819e95339c",
      "eae030ec44134cb39bd844dce77c1c84",
      "eabdf12ba0da45cb8c9a8fb947d02186",
      "6c32e48868194898a3500b55aa4d5a32",
      "2c8ea063682745408ca3953d867d2f86",
      "f87ac365b3484d1aa2db1bb6f5ab5850",
      "c8951cbe742041eeb511026e942bc791",
      "94d38c8405954b198cb83a5b3b56bccc",
      "4d8cdd7ba9eb4f909dd42d06347dfa7c",
      "3911f4668137442992ce5466c3ef1e44",
      "8ba1e086a4e84d4fb32b284c5aaaeb80",
      "b8ca8e4aeb5c4527a9643217582f0101",
      "40816dda5efc4bdab27e550c69b2f866",
      "361c030e0e644be5922596ecdc0858e6",
      "8a008077fa374d7aba587f4c377010d7",
      "929745cc57904be39f476dbff6e32b27",
      "eaf91be028244917a9d9129c7e5c957f",
      "e70dc15d51884f94974255f0bfa13f8f",
      "013ee9545df5476ab65425a9337f2251",
      "1e7973e87c8c4b6d8d36f6a766b22cbb",
      "31a5d52d9a7b4fcb8b79cfe6f25a9fc5",
      "cdca4476179a47989334f2d2c0b1c5a7",
      "00f40d0b11ba40b9bc17580eeb1fab5b",
      "b8f38c20992c4b53a2e19daf989b71da",
      "9b9943c4c59d46c59746d74b23f0831f",
      "89cbcfda267f4cbba158df2ff4f65ec0",
      "153ea11322b3473cbf15d97a39fa0a8a",
      "fcab3a290ddb4c5687f8cb0e1a8b8441",
      "d808de426d3f4602a9707f697a86b0f0",
      "d65f53807f1f4e56a88967d5760ef85e",
      "02bfbcc0204146408552322214fc165a",
      "ac9a40d5dbdc4cd6bf808966e24a9590",
      "99b37e5d50a443a5a4e3cf11c313bd70",
      "8b9df25615c3478695416a4d916ab281",
      "b8e64969fa0244039eb66ba477bc234e",
      "4feb2ee3205b450a906510e89cf8ed16",
      "f377b5712607499d95ba29796d82d116",
      "fe15c89f9f32495d9c5545705318e0fa",
      "de344ed89e7a4c668c2b355e34ccf077",
      "f8fa4c78ee354152a4154847f45a8c10",
      "9fadd27653b548f8a0829d8ba8c8518f",
      "8957bedbf98f4165ae2f7ba3fc7f542a",
      "ffc4c12e7efe4500bda40ab5fee44ffd",
      "cc6cedd44c014d5dabb61426744d1e25",
      "84e6c8763b9747e8b6af4f25a102c5e5"
     ]
    },
    "id": "6oZgGZTuCsjn",
    "outputId": "b0370f9f-0a36-4623-9eb4-0397d61d1873"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1158b0c59e64b1a8b06ff556ce8b258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae030ec44134cb39bd844dce77c1c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40816dda5efc4bdab27e550c69b2f866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f38c20992c4b53a2e19daf989b71da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87454 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e64969fa0244039eb66ba477bc234e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"  # KoELECTRA 분류기\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 토크나이즈 함수\n",
    "def encode_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"full_text\"],\n",
    "        truncation=True,\n",
    "        padding=False,      # Trainer 내부 collator에서 pad 수행\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "# HuggingFace Datasets로 변환 (labels 컬럼명으로 교체 필요)\n",
    "train_ds = Dataset.from_pandas(train_df.rename(columns={\"generated\":\"labels\"}), preserve_index=False)\n",
    "valid_ds = Dataset.from_pandas(valid_df.rename(columns={\"generated\":\"labels\"}), preserve_index=False)\n",
    "\n",
    "train_ds = train_ds.map(encode_batch, batched=True, remove_columns=[\"full_text\"])\n",
    "valid_ds = valid_ds.map(encode_batch, batched=True, remove_columns=[\"full_text\"])\n",
    "\n",
    "# 동적 패딩 collator (배치 내 최대 길이에 맞춰 pad)\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ae1e3374cec442eabd641bd26de1d8ab",
      "c7f1c19c24564cc0b744d06c8419d79d",
      "06e238e4ea0644f793059ae3ccc27bfb",
      "803f2b0e8e2044a89e62946d599a46bf",
      "22ab44fe365b435a8f678e9cb9e2be2b",
      "fc753e47f67c470cb0a4549fc7c27c09",
      "8ed5f365b88d49f5bf4335709b52df48",
      "01b774180c4a4ea8ac0534666034f238",
      "1558a0018a644cc8b784faac93035e8f",
      "67cc196bd76f4694a516e106374d3c9d",
      "88ea1b263f8840709b053ce7f895b5d4",
      "2ab63c9bbc1c46f485fd8c7459b954bd",
      "bb300031615045c5aab4037c8f3cc41a",
      "ec3cff57a0b948eeb99834f2663f98e1",
      "b3dc509cff094d0d9ff16cfdb54aef5f",
      "602aad74318c44638bbb8ba705038f2d",
      "946ac6d6c6d54a0d8b1828e3976c36c3",
      "524415412c1e4876b782e1019057e4ed",
      "1cc3b93ef37b4fbfa2fd03b4906aac65",
      "01a7c7528ae9451a88701e47a10e17de",
      "54bf799b4ff6410b981179d7d4db9bba",
      "ffcf3567cc8e4682b020a5d1c9144038"
     ]
    },
    "id": "ZKqFVBavC0nQ",
    "outputId": "37f74027-0315-4283-934f-2d525a1dcd73"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1e3374cec442eabd641bd26de1d8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/452M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab63c9bbc1c46f485fd8c7459b954bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/452M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 887,042 || all params: 113,809,924 || trainable%: 0.7794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): ElectraForSequenceClassification(\n",
       "      (electra): ElectraModel(\n",
       "        (embeddings): ElectraEmbeddings(\n",
       "          (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): ElectraEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x ElectraLayer(\n",
       "              (attention): ElectraAttention(\n",
       "                (self): ElectraSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): ElectraSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ElectraIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ElectraOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): ElectraClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): ElectraClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류 헤드 달린 ELECTRA 로드\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "# LoRA 설정 (ELECTRA/BERT류: attention의 query/value에 얹는 게 안전)\n",
    "lora_cfg = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,                 # 랭크 (작게→적은 VRAM / 너무 작으면 표현력↓)\n",
    "    lora_alpha=16,       # 스케일\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\",\"value\"]  # 필요시 [\"key\",\"dense\"] 추가도 가능\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "model.print_trainable_parameters()  # LoRA 파라미터만 학습되는지 확인\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rn-1RR99C5kK"
   },
   "outputs": [],
   "source": [
    "# 라벨 비율에 기반한 가중치 (0/1 분포 불균형시 효과적)\n",
    "neg = (train_df[\"generated\"] == 0).sum()\n",
    "pos = (train_df[\"generated\"] == 1).sum()\n",
    "pos_weight = neg / max(1, pos)   # 예: 11:1이면 ~11\n",
    "\n",
    "class_weights = torch.tensor([1.0, pos_weight], dtype=torch.float)\n",
    "\n",
    "# 클래스 가중치 (이미 계산했다고 가정)\n",
    "# class_weights = torch.tensor([1.0, pos_weight], dtype=torch.float)\n",
    "\n",
    "def weighted_loss(model, inputs, return_outputs=False, **kwargs):  # ← **kwargs 추가!\n",
    "    labels = inputs.pop(\"labels\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
    "    loss = loss_fn(logits, labels.long())\n",
    "    return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "55e16123d697463285bb3abe52212cb6",
      "4fed855f39ca41938ac56d2abb284d0c",
      "cff3e7a0e2524d28af3724e87d94d87f",
      "e94bb24cab714dd7bf5ae47eb9636825",
      "776b352432a647af9c886f132641f559",
      "2480fa607a3941e6a72017e46ccae3ec",
      "4eac7df322814a8f88b0a3cf1206110e",
      "4e0c90c5aead4aafaaf825df2b40cb9a",
      "d3bee0be484345ca94f4911da8535264",
      "0df0f6bd1a7f4a2db9ec75de6d70131c",
      "8624763cf4f44498abddee5accf7246c",
      "ee7b4b8913be433f868d517bbc41ad69",
      "836e5217ffb84b13afc2fd3f7ccc180e",
      "1f510f99d250483fa012896bb29af80c",
      "9bd2b97a21bc4373af7348184bec2f8e",
      "d6cc1c0151994d7aa207f3f4969236aa",
      "7ad0bb7cd201400299bd40f0c23a11eb",
      "e86a69a9a8f64ae4a8fce7a8504d6ea0",
      "39e8f6cada0d44038b28539aa7485a01",
      "7fa437f167404c068d34572f4f338c6e",
      "9eebe02c0c5248d789e11efe04aa6ad0",
      "4b3f2a972eb14fb68f8197e78c574369",
      "02c51beb212145a1854eec366589a328",
      "2e0a8d207cd14bfbb4d67976a4df1d0c",
      "a1110bd1c86f4c6fa9d238c307fb9891",
      "5ae34926a937444aaeae2acd02411c12",
      "c25b5e13ee044f0dbdb34e26b5f8fffa",
      "a3cb0753256a49d3894c5a0b273c44a4",
      "3c14f4bd1bff47db862183baa63baed1",
      "7131f8be38624d5ca1fb1afdd4bd7cd7",
      "4140dbb59b1440d68ca2a3987635fffb",
      "9e3309cadffd4899af7fb6b051f969d1",
      "dd692fb060e1469cbdefd17192136e45"
     ]
    },
    "id": "51oGrk9vC9Yh",
    "outputId": "dc598230-a71d-42fe-a858-c796b58a5230"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e16123d697463285bb3abe52212cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7b4b8913be433f868d517bbc41ad69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c51beb212145a1854eec366589a328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "metric_f1  = evaluate.load(\"f1\")\n",
    "metric_roc = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    import numpy as np\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "    preds = probs.argmax(axis=1)\n",
    "    acc = metric_acc.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    f1  = metric_f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "    try:\n",
    "        auc = metric_roc.compute(prediction_scores=probs[:,1], references=labels)[\"roc_auc\"]\n",
    "    except:\n",
    "        auc = float(\"nan\")\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1, \"auc\": auc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIyI0fn9IVkt"
   },
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):  # ← **kwargs\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
    "        loss = loss_fn(logits, labels.long())\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "8cfOhDWKDAMz",
    "outputId": "7354f688-300e-4627-cf65-064136c4a5f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-4256498411.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8199' max='8199' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8199/8199 2:10:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.345500</td>\n",
       "      <td>0.372205</td>\n",
       "      <td>0.804178</td>\n",
       "      <td>0.650759</td>\n",
       "      <td>0.914324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>0.307930</td>\n",
       "      <td>0.917370</td>\n",
       "      <td>0.786097</td>\n",
       "      <td>0.927282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.290044</td>\n",
       "      <td>0.920148</td>\n",
       "      <td>0.794744</td>\n",
       "      <td>0.940174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.292100</td>\n",
       "      <td>0.296735</td>\n",
       "      <td>0.924882</td>\n",
       "      <td>0.805624</td>\n",
       "      <td>0.943065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.278400</td>\n",
       "      <td>0.323055</td>\n",
       "      <td>0.864684</td>\n",
       "      <td>0.721758</td>\n",
       "      <td>0.950261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.246500</td>\n",
       "      <td>0.303842</td>\n",
       "      <td>0.892056</td>\n",
       "      <td>0.757324</td>\n",
       "      <td>0.952194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.253100</td>\n",
       "      <td>0.252513</td>\n",
       "      <td>0.944433</td>\n",
       "      <td>0.845534</td>\n",
       "      <td>0.953361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.309596</td>\n",
       "      <td>0.896584</td>\n",
       "      <td>0.764077</td>\n",
       "      <td>0.953974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8199, training_loss=0.2956816790408951, metrics={'train_runtime': 7802.5993, 'train_samples_per_second': 33.625, 'train_steps_per_second': 1.051, 'total_flos': 6.974527732612301e+16, 'train_loss': 0.2956816790408951, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=2e-4,                # LoRA만 학습하므로 base보다 조금 크게\n",
    "    per_device_train_batch_size=32,    # GPU 여유에 맞게 16~64 사이 조정\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.05,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=200,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    fp16=torch.cuda.is_available(),    # Colab T4/V100에서 Mixed Precision\n",
    "    report_to=\"none\",                  # (원하면 wandb 등으로 변경)\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 가중치 손실 적용\n",
    "trainer.compute_loss = weighted_loss\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4j17fgs3DHrt",
    "outputId": "35b153ca-3833-41b7-b38f-9dadf3f9546b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/LikeLion_NLP2/Small_Challenge/koelectra_lora_out/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/LikeLion_NLP2/Small_Challenge/koelectra_lora_out/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/LikeLion_NLP2/Small_Challenge/koelectra_lora_out/vocab.txt',\n",
       " '/content/drive/MyDrive/LikeLion_NLP2/Small_Challenge/koelectra_lora_out/added_tokens.json',\n",
       " '/content/drive/MyDrive/LikeLion_NLP2/Small_Challenge/koelectra_lora_out/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어댑터(LoRA)만 저장 → 베이스 모델 위에 merge 없이 로드 가능\n",
    "trainer.model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "# (선택) LoRA를 베이스에 merge하고 싶은 경우:\n",
    "# from peft import PeftModel\n",
    "# merged = PeftModel.from_pretrained(base_model, OUTPUT_DIR)\n",
    "# merged = merged.merge_and_unload()     # 가중치 병합\n",
    "# merged.save_pretrained(OUTPUT_DIR + \"_merged\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZiWbfwDx7Yk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
