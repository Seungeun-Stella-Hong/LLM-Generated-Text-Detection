{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZWqCI6Dh0Rsz",
    "outputId": "05e42a5f-ff2d-47e1-b41c-95328d3df4a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.3/506.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────\n",
    "# 0) Install / Imports\n",
    "# ─────────────────────────────────────────────────────────\n",
    "!pip install -q --upgrade transformers peft accelerate datasets torch tqdm\n",
    "\n",
    "import os, gc, numpy as np, pandas as pd, torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exOzvK551d0R",
    "outputId": "61f2caac-c08c-496c-c38c-3837686cf0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ccr27b_04qV"
   },
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────\n",
    "# 1) Config (학습 때와 동일해야 함)\n",
    "# ─────────────────────────────────────────────────────────\n",
    "BASE_MODEL  = \"klue/bert-base\"\n",
    "OUTPUT_DIR  = \"/content/drive/MyDrive/LikeLion_NLP2/Small_Challenge/\"      # ← 학습한 LoRA 어댑터 경로\n",
    "MAX_LEN     = 512                          # 창 최대 길이\n",
    "STRIDE      = 128                          # 슬라이딩 윈도우 stride\n",
    "BATCH_SIZE  = 64                           # 창 배치 추론 크기 (GPU에 맞게 조절)\n",
    "TITLE_BLEND = 0.0                          # 0.0=미사용 / 0.3=문단:타이틀평균=0.7:0.3로 블렌딩\n",
    "AGG_METHOD  = \"mean\"                       # \"mean\" | \"max\" (창 집계 방식)\n",
    "INPUT_CSV   = \"test.csv\"\n",
    "OUTPUT_CSV  = \"submission_LoRA_klue_bert-base.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373,
     "referenced_widgets": [
      "099f571c16194d1ab5708a8c09699b26",
      "333bf6c245814e238793df3ed96dca79",
      "17c7803eca3346269df35ad7b44a1cc2",
      "62d8bd93f24b4224ae1a3ad25e93c4df",
      "879d05c7377843c3ac5bb976eb5586b7",
      "6e8e56d5bf2f467aa41b0a7c9fb153d1",
      "f7edf8e848f845e8bcd8678416e7931f",
      "0bdc28bf7a9447a58bf1395132d8b8a0",
      "41486c3083ec49a2b712bdccbde4b81e",
      "465f66348c6243809780349d99adb8b0",
      "d0c7b2f92f374f6eb616133e51ef8b6c",
      "4780f98c484b4e6cb62586172898fe61",
      "072f646b83984252968af0e98b095c7b",
      "d4ef068da90748f0ab7b29555ce062e4",
      "0145adcb23cd4a468f7791d4e952b285",
      "c827f45ccc4d49c29bf53524e078e0af",
      "efadcb66196a489ca91d3f2d1e0010ac",
      "e304a86af6e141cabf6a3ee958cd0da4",
      "80bc0942aff94e26922957a79ad43471",
      "eab26bac07124b9d9dcc21c31ad69012",
      "53c098584a56444287948b4b814a7ece",
      "83bb705018c2407ca89031128e4df043",
      "757f53eace6743b581c709d3df6c7cfa",
      "61652d9a54d141dc9cdd00a07c9c79d2",
      "a122ef71bf7d418d8f4318c3b755373f",
      "c83501d3812d4c5d8e054e136e7c28ff",
      "51be961158604c74bc0211788aa0fadc",
      "df642e9fd553466c8837ef392eca8410",
      "18ee27d2ecc14c4392351b88ddaed6fa",
      "ea4ff54eb7dc44bab196feefed66ae94",
      "bdb002470c014436af166c4493308882",
      "fe910756d3ba496582b25d205078b2f7",
      "cd2b8faee3e843c38bad809d0ac1ff9d",
      "99533a4cf02c4ab99ab388c8392ef377",
      "232f5645f09547da8cf5ac0fb030216e",
      "4eaf6f1d7def410a8e6928afd0f0953b",
      "f8fb97d5daf345fbb505ea9d4f7f6b2e",
      "062145ee9982475a8ecd695fb573e7a0",
      "67c61507d4c540e18e17aba7224a87c7",
      "5ed9896df6dc47948e41fa26b541f1a5",
      "431c9566d1794dc1bd57ee811a7d9777",
      "d87f0d9b5c00432ca9681d166f5907e1",
      "33a7299dd64e49869d272fea39b17393",
      "3aa500c205a340d68ea6214695f23831",
      "38afca25515947b1bed543d8c7583623",
      "46367c0765ef43caae513c4404df6b16",
      "fa0f57e9d1464eb68462bc8bea18e7c6",
      "b961bd388dc849c594db94b0cd591a96",
      "e2b68e9ddc3d4c539137eec36d316aa9",
      "6a2948632a14418b818de22c7a6ae329",
      "7f06049414e64d5dbc4e3a7c07fca111",
      "55cc639041214d6d8867d8415a0c2a3a",
      "254bfeeec15a41409578ac6ad92b7ede",
      "c6d99f45a5a345b5932c29a016d58f0c",
      "913ef891ac0c4fe9ad8052acb94ab9a4",
      "9f5d5171092949fbafe4d39b18ddf2fa",
      "6d34273dda464217ab38b27d2f0bc653",
      "4381fabe305d40388b88f1f3346dadea",
      "dc8741c860e54d8f91fa2f43d124356e",
      "b1fa12ebe99a488ca051fdd35713264a",
      "92e047822026422992e1366f968921cc",
      "ad8981c63eff47a9be324e78897bd4ed",
      "b701d6472a05477b94ea493dbbdf82ca",
      "03f60a9db02f40978ef2e6642bf7abdd",
      "45738ec58700475195196a07ddb1562f",
      "ab0fb8b3df9c489faa8aa32bfbc2388f"
     ]
    },
    "id": "nQyDffEW06vJ",
    "outputId": "f894ad64-bbeb-4248-8e6c-963eb3da5923"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099f571c16194d1ab5708a8c09699b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4780f98c484b4e6cb62586172898fe61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757f53eace6743b581c709d3df6c7cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99533a4cf02c4ab99ab388c8392ef377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38afca25515947b1bed543d8c7583623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5d5171092949fbafe4d39b18ddf2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready on cuda\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────\n",
    "# 2) Load tokenizer & model (+ LoRA)\n",
    "# ─────────────────────────────────────────────────────────\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "base      = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=2).to(device)\n",
    "model     = PeftModel.from_pretrained(base, OUTPUT_DIR+\"skt_kobert_lora_out/\").to(device)\n",
    "model.eval()\n",
    "_ = torch.cuda.empty_cache()\n",
    "print(\"Model ready on\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9kiZ85n09LX",
    "outputId": "d8303f2a-75d4-4f30-cfc9-ca3b8d0b0de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID           title  paragraph_index  \\\n",
      "0  TEST_0000  공중 도덕의 의의와 필요성                0   \n",
      "1  TEST_0001  공중 도덕의 의의와 필요성                1   \n",
      "2  TEST_0002  공중 도덕의 의의와 필요성                2   \n",
      "\n",
      "                                      paragraph_text  \n",
      "0  도덕이란 원래 개인의 자각에서 출발해 자기 의지로써 행동하는 일이다. 그러므로 도덕...  \n",
      "1  도덕은 단순히 개인의 문제나 사회의 문제로 한정될 수 없다. 개인적인 측면과 사회적...  \n",
      "2  여기에 이른바 공중도덕은 실천적, 사회적 도덕의 한 부문이다. 즉, 공중 도덕이라 ...  \n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────\n",
    "# 3) Read test.csv (expected columns: ID, title, paragraph_index, paragraph_text)\n",
    "# ─────────────────────────────────────────────────────────\n",
    "test_df = pd.read_csv(OUTPUT_DIR+INPUT_CSV)\n",
    "\n",
    "required_cols = {\"ID\",\"title\",\"paragraph_index\",\"paragraph_text\"}\n",
    "missing = required_cols - set(test_df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"test.csv missing columns: {missing}\")\n",
    "\n",
    "# NaN 방지\n",
    "test_df[\"paragraph_text\"] = test_df[\"paragraph_text\"].astype(str).fillna(\"\")\n",
    "print(test_df.head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o141TwXq1AAF"
   },
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────\n",
    "# 4) Sliding-window inference for a single paragraph\n",
    "# ─────────────────────────────────────────────────────────\n",
    "@torch.no_grad()\n",
    "def predict_paragraph(text: str, max_len=MAX_LEN, stride=STRIDE, agg=AGG_METHOD):\n",
    "    # 토큰 ID로 길이 판단\n",
    "    enc = tokenizer(text, add_special_tokens=True, return_offsets_mapping=False)\n",
    "    ids = enc[\"input_ids\"]\n",
    "\n",
    "    # 짧으면 원샷\n",
    "    if len(ids) <= max_len:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len).to(device)\n",
    "        logits = model(**inputs).logits\n",
    "        prob_ai = softmax(logits, dim=1)[0, 1].item()\n",
    "        return float(prob_ai)\n",
    "\n",
    "    # 길면 창으로 분할\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(ids):\n",
    "        end = min(start + max_len, len(ids))\n",
    "        chunk_ids = ids[start:end]\n",
    "        chunks.append(chunk_ids)\n",
    "        if end == len(ids): break\n",
    "        start = end - stride  # 겹치게 이동\n",
    "\n",
    "    # 창 단위 배치 추론\n",
    "    probs = []\n",
    "    for i in range(0, len(chunks), BATCH_SIZE):\n",
    "        batch = chunks[i:i+BATCH_SIZE]\n",
    "        inputs = {\"input_ids\": batch, \"attention_mask\": [[1]*len(x) for x in batch]}\n",
    "        inputs = tokenizer.pad(inputs, return_tensors=\"pt\").to(device)\n",
    "        logits = model(**inputs).logits\n",
    "        batch_probs = softmax(logits, dim=1)[:, 1].detach().cpu().numpy().tolist()\n",
    "        probs.extend(batch_probs)\n",
    "\n",
    "    return float(np.max(probs) if agg == \"max\" else np.mean(probs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "d987bba926aa42809a763c91ce1fb78f",
      "afac300317454888b647886219a9b14d",
      "de1ddc4c2e804686b5b195f79620221e",
      "a840c142fdf54fb0bf4e50351b9817fa",
      "4b7363e913c842a8b0279ae380e19083",
      "fdf8b1533e0649f2bd0f1fd176b234af",
      "10154b6c587446729567f3bf824a312a",
      "e45abe90853c4a1ab9344f94186d692c",
      "4b952cbc867449efb904a3b6c64f53a1",
      "42dd8bf397114d74bae3d7b734ffe5ea",
      "9b943900368244fb83ab11d5813dfe46"
     ]
    },
    "id": "Fx3tXo0C1CP9",
    "outputId": "8f6c6bf8-e70d-4207-f81a-edc1456cf638"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d987bba926aa42809a763c91ce1fb78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/1962 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────\n",
    "# 5) Predict all rows\n",
    "# ─────────────────────────────────────────────────────────\n",
    "probs = []\n",
    "for text in tqdm(test_df[\"paragraph_text\"].tolist(), desc=\"Predicting\"):\n",
    "    probs.append(predict_paragraph(text))\n",
    "\n",
    "test_df[\"prob_ai\"] = probs  # 0~1 확률\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7l097coI1Dc1"
   },
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────\n",
    "# 6) (Optional) title-level blending (동일 title 평균과 섞기)\n",
    "# ─────────────────────────────────────────────────────────\n",
    "if TITLE_BLEND > 0.0:\n",
    "    title_mean = test_df.groupby(\"title\")[\"prob_ai\"].transform(\"mean\")\n",
    "    test_df[\"prob_ai\"] = (1.0 - TITLE_BLEND) * test_df[\"prob_ai\"] + TITLE_BLEND * title_mean\n",
    "    print(f\"title-level blending applied with weight={TITLE_BLEND}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "BJggv9LI1Es2",
    "outputId": "ca7896e9-b570-4e65-db67-873c91ebbec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: (1962, 2) -> submission_LoRA_klue_bert-base.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"submission\",\n  \"rows\": 1962,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1962,\n        \"samples\": [\n          \"TEST_1096\",\n          \"TEST_0572\",\n          \"TEST_0450\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32065761936986176,\n        \"min\": 0.004984610714018345,\n        \"max\": 0.9992382526397705,\n        \"num_unique_values\": 1959,\n        \"samples\": [\n          0.04063365235924721,\n          0.016018712893128395,\n          0.9971876740455627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "submission"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-436051db-152d-43a9-829b-09a7d712ac99\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0.068374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0.163658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0.030766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>0.163549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>0.294997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-436051db-152d-43a9-829b-09a7d712ac99')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-436051db-152d-43a9-829b-09a7d712ac99 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-436051db-152d-43a9-829b-09a7d712ac99');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-bb54dfe1-9116-44e7-8a4b-44bf0ec00eb7\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb54dfe1-9116-44e7-8a4b-44bf0ec00eb7')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-bb54dfe1-9116-44e7-8a4b-44bf0ec00eb7 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          ID  generated\n",
       "0  TEST_0000   0.068374\n",
       "1  TEST_0001   0.163658\n",
       "2  TEST_0002   0.030766\n",
       "3  TEST_0003   0.163549\n",
       "4  TEST_0004   0.294997"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────\n",
    "# 7) Save submission.csv (id, generated)\n",
    "# ─────────────────────────────────────────────────────────\n",
    "submission = test_df[[\"ID\",\"prob_ai\"]].rename(columns={\"ID\":\"ID\", \"prob_ai\":\"generated\"})\n",
    "submission.to_csv(OUTPUT_DIR+OUTPUT_CSV, index=False)\n",
    "print(\"Saved:\", submission.shape, \"->\", OUTPUT_CSV)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-ZpIw4A2dIu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
